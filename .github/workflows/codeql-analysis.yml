name: "CodeQL Feature Extraction"

on:
  workflow_dispatch:

jobs:
  extract-features:
    runs-on: ubuntu-latest
    
    container:
      image: ubuntu:20.04
    
    permissions:
      security-events: write
      actions: read
      contents: read

    steps:
    # 步骤1: 检出代码
    - name: Checkout target source code
      uses: actions/checkout@v4
      with:
        ref: '50eed9b008e7eff012e788a8a328901f68373579'

    # 步骤2: 动态创建CodeQL查询文件
    - name: Create CodeQL Query File
      run: |
        mkdir -p ./.github/codeql-queries
        cat <<'EOF' > ./.github/codeql-queries/FeatureExtraction.ql
        /**
         * @name Extract Features for Cohesion Analysis (v2)
         * @description This query extracts all referenced symbols for each source file.
         * @kind table
         */
        import cpp

        from File f, Locatable ref, string featureType
        where
          (f.getExtension() = "cpp" or f.getExtension() = "h" or f.getExtension() = "hpp") and
          f.getRelativePath().matches("src/brpc/%") and
          (
            exists(Call c | c.getLocation().getFile() = f and ref = c.getTarget() and featureType = "FunctionCall") or
            exists(VariableAccess va | va.getLocation().getFile() = f and ref = va.getTarget() and featureType = "VariableAccess") or
            exists(TypeAccess ta | ta.getLocation().getFile() = f and ref = ta.getType() and featureType = "TypeAccess")
          ) and
          ref.toString() != ""
        select f.getRelativePath() as file, featureType, ref.toString() as feature
        EOF

    # 步骤3: 初始化CodeQL
    - name: Initialize CodeQL
      uses: github/codeql-action/init@v3
      with:
        languages: cpp
        queries: ./.github/codeql-queries/FeatureExtraction.ql
        # 我们需要一个可预测的数据库路径
        db-location: ./codeql-db

    # 步骤4: 在容器内安装依赖
    - name: Install dependencies in container
      run: |
        export DEBIAN_FRONTEND=noninteractive
        apt-get update
        apt-get install -y git ca-certificates python3 python3-pip
        apt-get install -y build-essential cmake libssl-dev protobuf-compiler libgflags-dev libleveldb-dev libprotobuf-dev libprotoc-dev

    # 步骤5: 编译项目
    - name: Build project
      run: |
        cmake .
        make -j2

    # 步骤6: 运行分析。这一步会生成二进制的.bqrs结果文件
    - name: Perform CodeQL Analysis
      uses: github/codeql-action/analyze@v3
      with:
        # 将结果输出到'results'目录
        output: results
        
    # ========================== 最终核心修改点 ==========================
    # 步骤7: (新) 使用CodeQL CLI直接将结果解码为CSV
    - name: Decode BQRS results to CSV
      # CodeQL CLI的路径在 $CODEQL_PATH/codeql
      # 我们告诉它，解码我们自定义查询的结果，格式是csv，输出到 features.csv
      run: $CODEQL_PATH/codeql bqrs decode --format=csv --output=features.csv results/custom-queries/FeatureExtraction.bqrs

    # 步骤8: (新) 将CSV转换为最终的JSON格式
    - name: Convert CSV to JSON
      run: |
        cat <<'PY_EOF' > csv_to_json.py
        import csv
        import json
        import sys
        from collections import defaultdict

        def csv_to_json(csv_path, json_path):
            features_by_file = defaultdict(set)
            with open(csv_path, 'r', newline='', encoding='utf-8') as csvfile:
                reader = csv.reader(csvfile)
                # 跳过表头
                next(reader, None) 
                for row in reader:
                    if len(row) == 3:
                        file, _, feature = row
                        features_by_file[file].add(feature)
            
            output_dict = {file: sorted(list(features)) for file, features in features_by_file.items()}
            
            with open(json_path, 'w', encoding='utf-8') as jsonfile:
                json.dump(output_dict, jsonfile, indent=2, ensure_ascii=False)
            
            print(f"Conversion successful. Processed {len(output_dict)} files.")
        
        if __name__ == "__main__":
            csv_to_json(sys.argv[1], sys.argv[2])
        PY_EOF

        python3 csv_to_json.py features.csv extracted_features.json
        
    # 步骤9: 上传最终的JSON文件
    - name: Upload final JSON artifact
      uses: actions/upload-artifact@v4
      with:
        name: extracted-features-json
        path: extracted_features.json
    # ==============================================================
